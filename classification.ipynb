{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALTEGRAD Challenge - Classification\n",
    "\n",
    "*Abderrahim AIT-AZZI, SÃ©bastien OHLEYER, Mickael SUTTON*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastienohleyer/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/sebastienohleyer/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Performing grid search\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from log import _check_log_directory,_initialise_model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"./data/\"\n",
    "log_dir = './log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to make log directory at ./log/06-02-2018_12-19-39\n"
     ]
    }
   ],
   "source": [
    "#initialize model directory\n",
    "log_name = (datetime.now().strftime('%d-%m-%Y_%H-%M-%S'))\n",
    "log_filepath = os.path.join(log_dir,log_name,'lighgb.csv')\n",
    "_check_log_directory(os.path.join(log_dir,log_name))\n",
    "_initialise_model_log(log_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data & features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_features import load_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train, features_test, data_train = load_features(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train= features_train.drop(['is_duplicate'],axis=1)\n",
    "X_test = features_test\n",
    "X_train=X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_train=X_train.fillna(value=0)\n",
    "X_test=X_test.replace([np.inf, -np.inf], np.nan)\n",
    "X_test=X_test.fillna(value=0)\n",
    "Y_train = data_train[\"is_duplicate\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['len_q1', 'len_q2', 'diff_len', 'len_char_q1', 'len_char_q2',\n",
       "       'len_word_q1', 'len_word_q2', 'common_words', 'fuzz_qratio',\n",
       "       'fuzz_WRatio',\n",
       "       ...\n",
       "       'num_v_q1', 'num_v_q2', 'num_s_q1', 'num_s_q2', 'num_u_q1', 'num_u_q2',\n",
       "       'num_k_q1', 'num_k_q2', 'num_q_q1', 'num_q_q2'],\n",
       "      dtype='object', length=155)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier LIGHTGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lgb_train import lgb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features on train matrix:  155\n",
      "Number of features on test matrix:  155\n"
     ]
    }
   ],
   "source": [
    "print('Number of features on train matrix: ',len(X_train.columns))\n",
    "print('Number of features on test matrix: ',len(X_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 2017\n",
    "lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'gbdt',\n",
    "        'device': 'cpu',\n",
    "        'feature_fraction': 0.486,\n",
    "        'num_leaves': 130,\n",
    "        'lambda_l2': 1.9,\n",
    "        'learning_rate': 0.01,\n",
    "        'num_boost_round': 5000,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'max_depth': 25,\n",
    "        'min_data_in_leaf': 15,\n",
    "        'subsample': 1,\n",
    "        'colsample_bytree': 1,\n",
    "        'verbose': 1,\n",
    "        'bagging_fraction_seed': RANDOM_SEED,\n",
    "        'feature_fraction_seed': RANDOM_SEED,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastienohleyer/anaconda3/envs/nlp/lib/python3.6/site-packages/lightgbm/engine.py:98: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/sebastienohleyer/anaconda3/envs/nlp/lib/python3.6/site-packages/lightgbm/engine.py:103: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 1535 rounds, training loss 0.035988, validation loss 0.116600\n",
      "Fold 2: 1337 rounds, training loss 0.041199, validation loss 0.122086\n",
      "Fold 3: 1191 rounds, training loss 0.045550, validation loss 0.123544\n",
      "Fold 4: 1493 rounds, training loss 0.036772, validation loss 0.121144\n",
      "Fold 5: 1037 rounds, training loss 0.051163, validation loss 0.127999\n",
      "Final CV val score: [0.11660031160060474, 0.12208592217243029, 0.12354444149821074, 0.12114379831145441, 0.12799896202824534]\n",
      "Final mean CV val score: 0.12227468712218911\n",
      "\n",
      "Make submission file...\n",
      "Submission file written !\n"
     ]
    }
   ],
   "source": [
    "feat_imp = lgb_train(X_train, X_test, Y_train, lgb_params, log_filepath, test_prediction=True, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>shortest_path_weighted</td>\n",
       "      <td>1645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    column  importance\n",
       "71  shortest_path_weighted        1645"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp[feat_imp['column']=='shortest_path_weighted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp.plot(kind='bar', )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Important note\n",
    "\n",
    "The LighGB algorithm has several random initialization and unfortunately, we did not manage to completely fix them to be able to reproduce exactly a prediction. That is why you will not be able to replicate our best submission. We are sincerely apologize for this problem.\n",
    "\n",
    "However, note that with the provided code you will be able to reproduce every feature, run the classifier and achieve a result really close to our best submission (a random initialization set apart). We are at your disposal to answer any question you might have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
