{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALTEGRAD Challenge - Classification\n",
    "\n",
    "*Abderrahim AIT-AZZI, SÃ©bastien OHLEYER, Mickael SUTTON*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastienohleyer/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/sebastienohleyer/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn import cross_validation, metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Performing grid search\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from log import _check_log_directory,_initialise_model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = \"./data/\"\n",
    "log_dir = './log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to make log directory at ./log/01-02-2018_19-31-39\n"
     ]
    }
   ],
   "source": [
    "#initialize model directory\n",
    "log_name = (datetime.now().strftime('%d-%m-%Y_%H-%M-%S'))\n",
    "log_filepath = os.path.join(log_dir,log_name,'lighgb.csv')\n",
    "_check_log_directory(os.path.join(log_dir,log_name))\n",
    "_initialise_model_log(log_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data & features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from load_features import load_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features_train, features_test, data_train = load_features(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train= features_train.drop(['is_duplicate'],axis=1)\n",
    "X_test = features_test\n",
    "X_train=X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_train=X_train.fillna(value=0)\n",
    "X_test=X_test.replace([np.inf, -np.inf], np.nan)\n",
    "X_test=X_test.fillna(value=0)\n",
    "Y_train = data_train[\"is_duplicate\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['len_q1', 'len_q2', 'diff_len', 'len_char_q1', 'len_char_q2',\n",
       "       'len_word_q1', 'len_word_q2', 'common_words', 'fuzz_qratio',\n",
       "       'fuzz_WRatio',\n",
       "       ...\n",
       "       'num_o_q1', 'num_o_q2', 'num_h_q1', 'num_h_q2', 'num_s_q1', 'num_s_q2',\n",
       "       'num_f_q1', 'num_f_q2', 'num_l_q1', 'num_l_q2'],\n",
       "      dtype='object', length=158)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier LIGHTGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lgb_train import lgb_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features on train matrix:  158\n",
      "Number of features on test matrix:  158\n"
     ]
    }
   ],
   "source": [
    "print('Number of features on train matrix: ',len(X_train.columns))\n",
    "print('Number of features on test matrix: ',len(X_test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Gridsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for num_leaves in [120,130,140]:\n",
    "    for lambda_l2 in [1.8,1.9,2]:\n",
    "        RANDOM_SEED = 2017\n",
    "        lgb_params = {\n",
    "            'objective': 'binary',\n",
    "            'metric': 'binary_logloss',\n",
    "            'boosting': 'gbdt',\n",
    "            'device': 'cpu',\n",
    "            'feature_fraction': 0.486,\n",
    "            'num_leaves': num_leaves,\n",
    "            'lambda_l2': lambda_l2,\n",
    "            'learning_rate': 0.01,\n",
    "            'num_boost_round': 5000,\n",
    "            'early_stopping_rounds': 50,\n",
    "            'max_depth': 25,\n",
    "            'min_data_in_leaf': 15,\n",
    "            'subsample': 1,\n",
    "            'colsample_bytree': 1,\n",
    "            'verbose': 1,\n",
    "            'bagging_fraction_seed': RANDOM_SEED,\n",
    "            'feature_fraction_seed': RANDOM_SEED,\n",
    "        }\n",
    "        print(lgb_params)\n",
    "        lgb_train(X_train, X_test, Y_train, lgb_params, log_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Abderrahim best parameters\n",
    "RANDOM_SEED = 2017\n",
    "lgb_params = {\n",
    "        'objective': 'binary',\n",
    "        'metric': 'binary_logloss',\n",
    "        'boosting': 'gbdt',\n",
    "        'device': 'cpu',\n",
    "        'feature_fraction': 0.486,\n",
    "        'num_leaves': 140,\n",
    "        'lambda_l2': 2,\n",
    "        'learning_rate': 0.01,\n",
    "        'num_boost_round': 5000,\n",
    "        'early_stopping_rounds': 50,\n",
    "        'max_depth': 25,\n",
    "        'min_data_in_leaf': 15,\n",
    "        'subsample': 1,\n",
    "        'colsample_bytree': 1,\n",
    "        'verbose': 1,\n",
    "        'bagging_fraction_seed': RANDOM_SEED,\n",
    "        'feature_fraction_seed': RANDOM_SEED,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#lgb_params = {\n",
    "#    'learning_rate': 0.005, 'colsample_bytree': 1, 'boosting': 'gbdt', 'feature_fraction': 0.486, \n",
    "#    'metric': 'binary_logloss', 'min_data_in_leaf': 15, 'verbose': 1, 'subsample': 1, 'bagging_fraction_seed': 2017, \n",
    "#    'objective': 'binary', 'num_leaves': 130, 'max_depth': 25, 'early_stopping_rounds': 50, 'lambda_l2': 1.5, \n",
    "#    'feature_fraction_seed': 2017, 'device': 'cpu', 'num_boost_round': 5000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting fold {fold_num + 1} of {kfold.n_splits}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastienohleyer/anaconda3/envs/nlp/lib/python3.6/site-packages/lightgbm/engine.py:98: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/sebastienohleyer/anaconda3/envs/nlp/lib/python3.6/site-packages/lightgbm/engine.py:103: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1: 1446 rounds, training loss 0.035507, validation loss 0.116387\n",
      "Fitting fold {fold_num + 1} of {kfold.n_splits}\n",
      "Fold 2: 1427 rounds, training loss 0.035771, validation loss 0.121752\n",
      "Fitting fold {fold_num + 1} of {kfold.n_splits}\n",
      "Fold 3: 1297 rounds, training loss 0.039282, validation loss 0.123209\n",
      "Fitting fold {fold_num + 1} of {kfold.n_splits}\n",
      "Fold 4: 1422 rounds, training loss 0.035729, validation loss 0.121296\n",
      "Fitting fold {fold_num + 1} of {kfold.n_splits}\n",
      "Fold 5: 1096 rounds, training loss 0.045651, validation loss 0.127562\n",
      "Final CV val score: [0.11638674224041103, 0.1217516816404173, 0.12320874240424384, 0.12129626367404682, 0.1275618977165923]\n",
      "Final mean CV val score: 0.12204106553514227\n",
      "\n",
      "Make submission file...\n",
      "Submission file written !\n"
     ]
    }
   ],
   "source": [
    "feat_imp = lgb_train(X_train, X_test, Y_train, lgb_params, log_filepath, test_prediction=True, num_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>shortest_path_weighted</td>\n",
       "      <td>1662</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    column  importance\n",
       "74  shortest_path_weighted        1662"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp[feat_imp['column']=='shortest_path_weighted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Manual CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_feat = X_train\n",
    "X_train_values=X_train[:60000].values\n",
    "y_train_values = Y_train[:60000]\n",
    "X_fold_val = X_train[60000:].values\n",
    "y_fold_val = Y_train[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastienohleyer/anaconda3/envs/nlp/lib/python3.6/site-packages/lightgbm/engine.py:98: UserWarning: Found `num_boost_round` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n",
      "/Users/sebastienohleyer/anaconda3/envs/nlp/lib/python3.6/site-packages/lightgbm/engine.py:103: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "lgb_params = lgb_params.copy()\n",
    "\n",
    "lgb_data_train = lgb.Dataset(X_train_values, y_train_values)\n",
    "lgb_data_val = lgb.Dataset(X_fold_val, y_fold_val)    \n",
    "evals_result = {}\n",
    "\n",
    "model = lgb.train(\n",
    "lgb_params,\n",
    "lgb_data_train,\n",
    "valid_sets=[lgb_data_train, lgb_data_val],\n",
    "evals_result=evals_result,\n",
    "num_boost_round=lgb_params['num_boost_round'],\n",
    "early_stopping_rounds=lgb_params['early_stopping_rounds'],\n",
    "verbose_eval=False,\n",
    ")\n",
    "fold_train_scores = evals_result['training'][lgb_params['metric']]\n",
    "fold_val_scores = evals_result['valid_1'][lgb_params['metric']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.038801477712497756\n",
      "0.12940948953510495\n"
     ]
    }
   ],
   "source": [
    "print(fold_train_scores[-1])\n",
    "print(fold_val_scores[-1])\n",
    "\n",
    "feat_imp = pd.DataFrame({\n",
    "'column': list(X_train.columns),\n",
    "'importance': model.feature_importance()}).sort_values(by='importance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>column</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>shortest_path_weighted</td>\n",
       "      <td>2071</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    column  importance\n",
       "74  shortest_path_weighted        2071"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_imp[feat_imp['column']=='shortest_path_weighted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nlp]",
   "language": "python",
   "name": "conda-env-nlp-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
