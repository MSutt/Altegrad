{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.layers import Dense, Input, LSTM, concatenate, Embedding\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from log import _check_log_directory,_initialise_model_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data\"\n",
    "log_dir = './log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove features\n",
    "features_train = pd.read_csv(os.path.join(data_dir,'train_features_glove.csv'), sep=',', encoding='latin-1')\n",
    "features_test = pd.read_csv(os.path.join(data_dir,'test_features_glove.csv'), sep=',', encoding='latin-1')\n",
    "features_train= features_train.drop(['question1', 'question2'], axis=1)\n",
    "features_test = features_test.drop(['id','qid1','qid2','question1', 'question2'], axis=1)\n",
    "data_train = pd.read_csv('./data/train.csv', sep=',',names = [\"id\", \"qid1\", \"qid2\", \"question1\",\"question2\",\"is_duplicate\"])\n",
    "Y_train=data_train[\"is_duplicate\"].values\n",
    "\n",
    "# Pagerank features\n",
    "pagerank_feats_train = pd.read_csv(os.path.join(data_dir,\"train_pagerank.csv\"), sep=',')\n",
    "pagerank_feats_test = pd.read_csv(os.path.join(data_dir,\"test_pagerank.csv\"), sep=',')\n",
    "\n",
    "# Question frequency\n",
    "train_question_freq = pd.read_csv(os.path.join(data_dir,'train_question_freq.csv'), sep=',', index_col=0)\n",
    "test_question_freq = pd.read_csv(os.path.join(data_dir,'test_question_freq.csv'), sep=',', index_col=0)\n",
    "\n",
    "# Intersection of questions\n",
    "train_question_inter= pd.read_csv(os.path.join(data_dir,'train_question_inter.csv'), sep=',', index_col=0)\n",
    "test_question_inter = pd.read_csv(os.path.join(data_dir,'test_question_inter.csv'), sep=',', index_col=0)\n",
    "\n",
    "# K-cores\n",
    "train_kcores = pd.read_csv(os.path.join(data_dir,'train_kcores.csv'), sep=',', index_col=0)\n",
    "test_kcores = pd.read_csv(os.path.join(data_dir,'test_kcores.csv'), sep=',', index_col=0)\n",
    "\n",
    "# question K-cores\n",
    "train_question_kcores = pd.read_csv(os.path.join(data_dir,'train_question_kcores.csv'), sep=',', index_col=0)\n",
    "test_question_kcores = pd.read_csv(os.path.join(data_dir,'test_question_kcores.csv'), sep=',', index_col=0)\n",
    "\n",
    "# TF-IDF\n",
    "train_tfidf = pd.read_csv(os.path.join(data_dir,'train_tfidf.csv'), sep=',', index_col=0)\n",
    "test_tfidf = pd.read_csv(os.path.join(data_dir,'test_tfidf.csv'), sep=',', index_col=0)\n",
    "\n",
    "# Graph features\n",
    "train_graph_feat = pd.read_csv(os.path.join(data_dir,'train_graph_feat.csv'), sep=',', index_col=0)\n",
    "test_graph_feat = pd.read_csv(os.path.join(data_dir,'test_graph_feat.csv'), sep=',', index_col=0)\n",
    "\n",
    "# Bigram feature\n",
    "train_bigram_feat = pd.read_csv(os.path.join(data_dir,'train_bigram_feat.csv'), sep=',', index_col=0)\n",
    "test_bigram_feat = pd.read_csv(os.path.join(data_dir,'test_bigram_feat.csv'), sep=',', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Pagerank features\n",
    "features_train[[\"q1_pr\",\"q2_pr\"]]=pagerank_feats_train[[\"q1_pr\",\"q2_pr\"]]\n",
    "features_test[[\"q1_pr\",\"q2_pr\"]]=pagerank_feats_test[[\"q1_pr\",\"q2_pr\"]]\n",
    "\n",
    "# Add question frequency features\n",
    "features_train[[\"q1_hash\",\"q2_hash\",\"q1_freq\",\"q2_freq\"]]=train_question_freq[[\"q1_hash\",\"q2_hash\",\"q1_freq\",\"q2_freq\"]]\n",
    "features_test[[\"q1_hash\",\"q2_hash\",\"q1_freq\",\"q2_freq\"]]=test_question_freq[[\"q1_hash\",\"q2_hash\",\"q1_freq\",\"q2_freq\"]]\n",
    "\n",
    "# Add intersection of questions features\n",
    "features_train['q1_q2_intersect']=train_question_inter['q1_q2_intersect']\n",
    "features_test['q1_q2_intersect']=test_question_inter['q1_q2_intersect']\n",
    "\n",
    "# Add K-cores\n",
    "features_train[[\"core1\",\"core2\",\"core3\"]] = train_kcores[[\"core1\",\"core2\",\"core3\"]]\n",
    "features_test[[\"core1\",\"core2\",\"core3\"]] = test_kcores[[\"core1\",\"core2\",\"core3\"]]\n",
    "\n",
    "# Add question K-cores features\n",
    "features_train[['q1_kcores', 'q2_kcores', 'q1_q2_kcores_ratio', 'q1_q2_kcores_diff', \n",
    "                'q1_q2_kcores_diff_normed']]=train_question_kcores[['q1_kcores', 'q2_kcores', 'q1_q2_kcores_ratio', 'q1_q2_kcores_diff', 'q1_q2_kcores_diff_normed']]\n",
    "features_test[['q1_kcores', 'q2_kcores', 'q1_q2_kcores_ratio', 'q1_q2_kcores_diff', \n",
    "               'q1_q2_kcores_diff_normed']]=test_question_kcores[['q1_kcores', 'q2_kcores', 'q1_q2_kcores_ratio', 'q1_q2_kcores_diff', 'q1_q2_kcores_diff_normed']]\n",
    "\n",
    "# Add TF-IDF features\n",
    "features_train[['word_match','tfidf_wm','tfidf_wm_stops','jaccard','wc_diff','wc_ratio','wc_diff_unique','wc_ratio_unique','wc_diff_unq_stop','wc_ratio_unique_stop','same_start',\n",
    " 'char_diff','char_diff_unq_stop','total_unique_words','total_unq_words_stop','char_ratio']]=train_tfidf[['word_match','tfidf_wm','tfidf_wm_stops','jaccard','wc_diff','wc_ratio','wc_diff_unique','wc_ratio_unique','wc_diff_unq_stop','wc_ratio_unique_stop','same_start',\n",
    " 'char_diff','char_diff_unq_stop','total_unique_words','total_unq_words_stop','char_ratio']]\n",
    "features_test[['word_match','tfidf_wm','tfidf_wm_stops','jaccard','wc_diff','wc_ratio','wc_diff_unique','wc_ratio_unique','wc_diff_unq_stop','wc_ratio_unique_stop','same_start',\n",
    " 'char_diff','char_diff_unq_stop','total_unique_words','total_unq_words_stop','char_ratio']]=test_tfidf[['word_match','tfidf_wm','tfidf_wm_stops','jaccard','wc_diff','wc_ratio','wc_diff_unique','wc_ratio_unique','wc_diff_unq_stop','wc_ratio_unique_stop','same_start',\n",
    " 'char_diff','char_diff_unq_stop','total_unique_words','total_unq_words_stop','char_ratio']]\n",
    "\n",
    "# Add graph features\n",
    "features_train[['q1_neigh','q2_neigh','common_neigh', 'distinct_neigh', 'clique_size']] = train_graph_feat[['q1_neigh','q2_neigh','common_neigh', 'distinct_neigh', 'clique_size']]\n",
    "features_test[['q1_neigh','q2_neigh','common_neigh', 'distinct_neigh', 'clique_size']] = test_graph_feat[['q1_neigh','q2_neigh','common_neigh', 'distinct_neigh', 'clique_size']]\n",
    "\n",
    "# Add bigram features\n",
    "features_train[['bigram_coocurence','bigram_distinct','bigram_nostpwrd_coocurence', 'bigram_nostpwrd_distinct']] = train_bigram_feat[['bigram_coocurence','bigram_distinct','bigram_nostpwrd_coocurence', 'bigram_nostpwrd_distinct']]\n",
    "features_test[['bigram_coocurence','bigram_distinct','bigram_nostpwrd_coocurence', 'bigram_nostpwrd_distinct']] = test_bigram_feat[['bigram_coocurence','bigram_distinct','bigram_nostpwrd_coocurence', 'bigram_nostpwrd_distinct']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_train\n",
    "X_test = features_test\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.fillna(value=0)\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "X_test = X_test.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                 u'is_duplicate',                        u'len_q1',\n",
       "                              u'len_q2',                      u'diff_len',\n",
       "                         u'len_char_q1',                   u'len_char_q2',\n",
       "                         u'len_word_q1',                   u'len_word_q2',\n",
       "                        u'common_words',                   u'fuzz_qratio',\n",
       "                         u'fuzz_WRatio',            u'fuzz_partial_ratio',\n",
       "        u'fuzz_partial_token_set_ratio', u'fuzz_partial_token_sort_ratio',\n",
       "                u'fuzz_token_set_ratio',         u'fuzz_token_sort_ratio',\n",
       "                                 u'wmd',                      u'norm_wmd',\n",
       "                     u'cosine_distance',            u'cityblock_distance',\n",
       "                    u'jaccard_distance',             u'canberra_distance',\n",
       "                  u'euclidean_distance',            u'minkowski_distance',\n",
       "                 u'braycurtis_distance',                    u'skew_q1vec',\n",
       "                          u'skew_q2vec',                     u'kur_q1vec',\n",
       "                           u'kur_q2vec',                         u'q1_pr',\n",
       "                               u'q2_pr',                       u'q1_hash',\n",
       "                             u'q2_hash',                       u'q1_freq',\n",
       "                             u'q2_freq',               u'q1_q2_intersect',\n",
       "                               u'core1',                         u'core2',\n",
       "                               u'core3',                     u'q1_kcores',\n",
       "                           u'q2_kcores',            u'q1_q2_kcores_ratio',\n",
       "                   u'q1_q2_kcores_diff',      u'q1_q2_kcores_diff_normed',\n",
       "                          u'word_match',                      u'tfidf_wm',\n",
       "                      u'tfidf_wm_stops',                       u'jaccard',\n",
       "                             u'wc_diff',                      u'wc_ratio',\n",
       "                      u'wc_diff_unique',               u'wc_ratio_unique',\n",
       "                    u'wc_diff_unq_stop',          u'wc_ratio_unique_stop',\n",
       "                          u'same_start',                     u'char_diff',\n",
       "                  u'char_diff_unq_stop',            u'total_unique_words',\n",
       "                u'total_unq_words_stop',                    u'char_ratio',\n",
       "                            u'q1_neigh',                      u'q2_neigh',\n",
       "                        u'common_neigh',                u'distinct_neigh',\n",
       "                         u'clique_size',             u'bigram_coocurence',\n",
       "                     u'bigram_distinct',    u'bigram_nostpwrd_coocurence',\n",
       "            u'bigram_nostpwrd_distinct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "905"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X\n",
    "Y = data.pop('is_duplicate')\n",
    "test_size = 0.1\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(data, Y, test_size=test_size)\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of features = 68\n"
     ]
    }
   ],
   "source": [
    "print \"number of features =\", X_train.values.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72090 samples, validate on 8010 samples\n",
      "Epoch 1/20\n",
      "72090/72090 [==============================] - 15s 206us/step - loss: 0.5816 - val_loss: 0.5462\n",
      "Epoch 2/20\n",
      "72090/72090 [==============================] - 14s 198us/step - loss: 0.5027 - val_loss: 0.4684\n",
      "Epoch 3/20\n",
      "72090/72090 [==============================] - 13s 175us/step - loss: 0.4251 - val_loss: 0.4062\n",
      "Epoch 4/20\n",
      "72090/72090 [==============================] - 11s 150us/step - loss: 0.3623 - val_loss: 0.3653\n",
      "Epoch 5/20\n",
      "72090/72090 [==============================] - 9s 122us/step - loss: 0.3232 - val_loss: 0.3619\n",
      "Epoch 6/20\n",
      "72090/72090 [==============================] - 9s 118us/step - loss: 0.3108 - val_loss: 0.2913\n",
      "Epoch 7/20\n",
      "72090/72090 [==============================] - 7s 104us/step - loss: 0.2927 - val_loss: 0.2777\n",
      "Epoch 8/20\n",
      "72090/72090 [==============================] - 9s 118us/step - loss: 0.2828 - val_loss: 0.2756\n",
      "Epoch 9/20\n",
      "72090/72090 [==============================] - 10s 132us/step - loss: 0.2843 - val_loss: 0.2631\n",
      "Epoch 10/20\n",
      "72090/72090 [==============================] - 9s 125us/step - loss: 0.2744 - val_loss: 0.2595\n",
      "Epoch 11/20\n",
      "72090/72090 [==============================] - 9s 120us/step - loss: 0.2794 - val_loss: 0.2534\n",
      "Epoch 12/20\n",
      "72090/72090 [==============================] - 9s 126us/step - loss: 0.2761 - val_loss: 0.3159\n",
      "Epoch 13/20\n",
      "72090/72090 [==============================] - 9s 130us/step - loss: 0.2764 - val_loss: 0.2630\n",
      "Epoch 14/20\n",
      "72090/72090 [==============================] - 8s 116us/step - loss: 0.2742 - val_loss: 0.2679\n",
      "Epoch 15/20\n",
      "72090/72090 [==============================] - 8s 106us/step - loss: 0.2781 - val_loss: 0.2857\n",
      "Epoch 16/20\n",
      "72090/72090 [==============================] - 10s 138us/step - loss: 0.2756 - val_loss: 0.2601\n",
      "Epoch 17/20\n",
      "72090/72090 [==============================] - 9s 123us/step - loss: 0.2735 - val_loss: 0.2680\n",
      "Epoch 18/20\n",
      "72090/72090 [==============================] - 9s 122us/step - loss: 0.2672 - val_loss: 0.2840\n",
      "Epoch 19/20\n",
      "72090/72090 [==============================] - 9s 128us/step - loss: 0.2711 - val_loss: 0.2627\n",
      "Epoch 20/20\n",
      "72090/72090 [==============================] - 9s 124us/step - loss: 0.2648 - val_loss: 0.2562\n"
     ]
    }
   ],
   "source": [
    "X_train_np = X_train.values\n",
    "X_val_np = X_val.values\n",
    "Y_train_np = Y_train.values\n",
    "Y_val_np  = Y_val.values\n",
    "\n",
    "shape = (X_train_np.shape[1],)\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='sigmoid',input_shape=shape))\n",
    "model.add(Dense(1,activation = \"sigmoid\"))\n",
    "opt = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "history = model.fit(X_train_np,Y_train_np,epochs=20,validation_data =(X_val_np,Y_val_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72090 samples, validate on 8010 samples\n",
      "Epoch 1/15\n",
      "72090/72090 [==============================] - 10s 142us/step - loss: 0.2353 - val_loss: 0.2438\n",
      "Epoch 2/15\n",
      "72090/72090 [==============================] - 9s 120us/step - loss: 0.2329 - val_loss: 0.2411\n",
      "Epoch 3/15\n",
      "72090/72090 [==============================] - 9s 123us/step - loss: 0.2298 - val_loss: 0.2382\n",
      "Epoch 4/15\n",
      "72090/72090 [==============================] - 9s 120us/step - loss: 0.2284 - val_loss: 0.2381\n",
      "Epoch 5/15\n",
      "72090/72090 [==============================] - 9s 123us/step - loss: 0.2286 - val_loss: 0.2404\n",
      "Epoch 6/15\n",
      "72090/72090 [==============================] - 8s 117us/step - loss: 0.2290 - val_loss: 0.2386\n",
      "Epoch 7/15\n",
      "72090/72090 [==============================] - 8s 116us/step - loss: 0.2280 - val_loss: 0.2350\n",
      "Epoch 8/15\n",
      "72090/72090 [==============================] - 8s 115us/step - loss: 0.2257 - val_loss: 0.2364\n",
      "Epoch 9/15\n",
      "72090/72090 [==============================] - 8s 116us/step - loss: 0.2246 - val_loss: 0.2320\n",
      "Epoch 10/15\n",
      "72090/72090 [==============================] - 9s 122us/step - loss: 0.2236 - val_loss: 0.2438\n",
      "Epoch 11/15\n",
      "72090/72090 [==============================] - 8s 110us/step - loss: 0.2235 - val_loss: 0.2330\n",
      "Epoch 12/15\n",
      "72090/72090 [==============================] - 8s 114us/step - loss: 0.2233 - val_loss: 0.2338\n",
      "Epoch 13/15\n",
      "72090/72090 [==============================] - 8s 117us/step - loss: 0.2237 - val_loss: 0.2333\n",
      "Epoch 14/15\n",
      "72090/72090 [==============================] - 8s 112us/step - loss: 0.2239 - val_loss: 0.2364\n",
      "Epoch 15/15\n",
      "72090/72090 [==============================] - 8s 117us/step - loss: 0.2235 - val_loss: 0.2393\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.00001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "history2 = model.fit(X_train_np,Y_train_np,epochs=15,validation_data =(X_val_np,Y_val_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAELCAYAAAAoUKpTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\njDGmXf8fb+o+KoJ5cusAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14391a1d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history[\"loss\"]+ history2.history[\"loss\"])\n",
    "plt.plot(history.history[\"val_loss\"]+ history2.history[\"val_loss\"])\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Apres ici ce sont des tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul de la taille maximale des questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_train = data_train[\"question1\"]\n",
    "q2_train = data_train[\"question2\"]\n",
    "q1_test = data_test[\"question1\"]\n",
    "q2_test = data_test[\"question2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_train_sp = [q.split() for q in q1_train]\n",
    "q2_train_sp = [q.split() for q in q2_train]\n",
    "q1_test_sp = [q.split() for q in q1_test]\n",
    "q2_test_sp = [q.split() for q in q2_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n",
      "58\n",
      "73\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print max([len(q) for q in q1_train_sp])\n",
    "print max([len(q) for q in q2_train_sp])\n",
    "print max([len(q) for q in q1_test_sp])\n",
    "Tprint max([len(q) for q in q2_test_sp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 73"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_train = pd.read_csv('data/train_features_glove.csv', sep=',', encoding='latin-1')\n",
    "features_test = pd.read_csv('data/test_features_glove.csv', sep=',', encoding='latin-1')\n",
    "data_train = pd.read_csv('train.csv', sep=',',names = [\"id\", \"qid1\", \"qid2\", \"question1\",\"question2\",\"is_duplicate\"])\n",
    "Y = data_train.pop(\"is_duplicate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = features_train\n",
    "X_test = features_test\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.fillna(value=0)\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "X_test = X_test.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X\n",
    "#data.pop(\"question1\")\n",
    "#data.pop(\"question2\")\n",
    "#data.pop(\"is_duplicate\")\n",
    "X_train= features_train.drop(['question1','question2','is_duplicate','cosine_distance','jaccard_distance','euclidean_distance','norm_wmd','fuzz_WRatio','len_word_q2','len_word_q1','minkowski_distance','braycurtis_distance'], axis=1)\n",
    "test_size = 0.1\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(data, Y, test_size=test_size)\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 72090 samples, validate on 8010 samples\n",
      "Epoch 1/10\n",
      "72090/72090 [==============================] - 273s 4ms/step - loss: 0.5719 - val_loss: 0.5572\n",
      "Epoch 2/10\n",
      "72090/72090 [==============================] - 162s 2ms/step - loss: 0.5489 - val_loss: 0.5507\n",
      "Epoch 3/10\n",
      "72090/72090 [==============================] - 157s 2ms/step - loss: 0.5407 - val_loss: 0.5414\n",
      "Epoch 4/10\n",
      "72090/72090 [==============================] - 157s 2ms/step - loss: 0.5368 - val_loss: 0.5550\n",
      "Epoch 5/10\n",
      "72090/72090 [==============================] - 158s 2ms/step - loss: 0.5318 - val_loss: 0.5314\n",
      "Epoch 6/10\n",
      "72090/72090 [==============================] - 169s 2ms/step - loss: 0.5290 - val_loss: 0.5328\n",
      "Epoch 7/10\n",
      "72090/72090 [==============================] - 288s 4ms/step - loss: 0.5247 - val_loss: 0.5434\n",
      "Epoch 8/10\n",
      "72090/72090 [==============================] - 358s 5ms/step - loss: 0.5230 - val_loss: 0.5263\n",
      "Epoch 9/10\n",
      "72090/72090 [==============================] - 414s 6ms/step - loss: 0.5204 - val_loss: 0.5331\n",
      "Epoch 10/10\n",
      "72090/72090 [==============================] - 322s 4ms/step - loss: 0.5190 - val_loss: 0.5454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11357bbd0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "X_train_np = X_train.values\n",
    "X_val_np = X_val.values\n",
    "Y_train_np = Y_train.values\n",
    "Y_val_np  = Y_val.values\n",
    "\n",
    "shape = (X_train_np.shape[1],)\n",
    "model = Sequential()\n",
    "model.add(Dense(1024, activation='sigmoid',input_shape=shape))\n",
    "model.add(Dense(1024, activation='sigmoid'))\n",
    "model.add(Dense(1024, activation='sigmoid'))\n",
    "#model.add(Dense(1024, activation='tanh'))\n",
    "model.add(Dense(1,activation = \"sigmoid\"))\n",
    "opt = keras.optimizers.Adam(lr=0.0001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=\"adam\")\n",
    "model.fit(X_train_np,Y_train_np,nb_epoch=10,validation_data =(X_val_np,Y_val_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>len_char_q2</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>common_words</th>\n",
       "      <th>fuzz_qratio</th>\n",
       "      <th>fuzz_WRatio</th>\n",
       "      <th>...</th>\n",
       "      <th>cityblock_distance</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>skew_q1vec</th>\n",
       "      <th>skew_q2vec</th>\n",
       "      <th>kur_q1vec</th>\n",
       "      <th>kur_q2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61470</th>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.397956</td>\n",
       "      <td>-5.397956</td>\n",
       "      <td>50.999782</td>\n",
       "      <td>50.999782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52652</th>\n",
       "      <td>115</td>\n",
       "      <td>39</td>\n",
       "      <td>76</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>38</td>\n",
       "      <td>86</td>\n",
       "      <td>...</td>\n",
       "      <td>6.248636</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157.564608</td>\n",
       "      <td>0.454233</td>\n",
       "      <td>0.206826</td>\n",
       "      <td>0.378103</td>\n",
       "      <td>-7.113229</td>\n",
       "      <td>-4.746818</td>\n",
       "      <td>65.892186</td>\n",
       "      <td>38.016010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62647</th>\n",
       "      <td>104</td>\n",
       "      <td>99</td>\n",
       "      <td>5</td>\n",
       "      <td>23</td>\n",
       "      <td>27</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "      <td>62</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td>6.700246</td>\n",
       "      <td>1.0</td>\n",
       "      <td>160.466555</td>\n",
       "      <td>0.477150</td>\n",
       "      <td>0.213258</td>\n",
       "      <td>0.390585</td>\n",
       "      <td>-5.871459</td>\n",
       "      <td>-4.239369</td>\n",
       "      <td>46.448806</td>\n",
       "      <td>28.991935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>38</td>\n",
       "      <td>42</td>\n",
       "      <td>-4</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "      <td>...</td>\n",
       "      <td>11.052061</td>\n",
       "      <td>1.0</td>\n",
       "      <td>166.510503</td>\n",
       "      <td>0.815223</td>\n",
       "      <td>0.377213</td>\n",
       "      <td>0.485439</td>\n",
       "      <td>-0.580091</td>\n",
       "      <td>-2.302947</td>\n",
       "      <td>1.765170</td>\n",
       "      <td>14.246697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5464</th>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>58</td>\n",
       "      <td>...</td>\n",
       "      <td>8.190089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>153.197744</td>\n",
       "      <td>0.605530</td>\n",
       "      <td>0.279310</td>\n",
       "      <td>0.394413</td>\n",
       "      <td>-3.854237</td>\n",
       "      <td>-2.359391</td>\n",
       "      <td>31.850361</td>\n",
       "      <td>19.318841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       len_q1  len_q2  diff_len  len_char_q1  len_char_q2  len_word_q1  \\\n",
       "61470      30      26         4           15           13            6   \n",
       "52652     115      39        76           23           16           25   \n",
       "62647     104      99         5           23           27           16   \n",
       "605        38      42        -4           15           16            7   \n",
       "5464       43      35         8           20           16            8   \n",
       "\n",
       "       len_word_q2  common_words  fuzz_qratio  fuzz_WRatio    ...      \\\n",
       "61470            5             2           67           70    ...       \n",
       "52652            9             6           38           86    ...       \n",
       "62647           16             6           62           62    ...       \n",
       "605              7             3           79           79    ...       \n",
       "5464             7             2           58           58    ...       \n",
       "\n",
       "       cityblock_distance  jaccard_distance  canberra_distance  \\\n",
       "61470            0.000000               0.0           0.000000   \n",
       "52652            6.248636               1.0         157.564608   \n",
       "62647            6.700246               1.0         160.466555   \n",
       "605             11.052061               1.0         166.510503   \n",
       "5464             8.190089               1.0         153.197744   \n",
       "\n",
       "       euclidean_distance  minkowski_distance  braycurtis_distance  \\\n",
       "61470            0.000000            0.000000             0.000000   \n",
       "52652            0.454233            0.206826             0.378103   \n",
       "62647            0.477150            0.213258             0.390585   \n",
       "605              0.815223            0.377213             0.485439   \n",
       "5464             0.605530            0.279310             0.394413   \n",
       "\n",
       "       skew_q1vec  skew_q2vec  kur_q1vec  kur_q2vec  \n",
       "61470   -5.397956   -5.397956  50.999782  50.999782  \n",
       "52652   -7.113229   -4.746818  65.892186  38.016010  \n",
       "62647   -5.871459   -4.239369  46.448806  28.991935  \n",
       "605     -0.580091   -2.302947   1.765170  14.246697  \n",
       "5464    -3.854237   -2.359391  31.850361  19.318841  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>len_q1</th>\n",
       "      <th>len_q2</th>\n",
       "      <th>diff_len</th>\n",
       "      <th>len_char_q1</th>\n",
       "      <th>len_char_q2</th>\n",
       "      <th>len_word_q1</th>\n",
       "      <th>len_word_q2</th>\n",
       "      <th>...</th>\n",
       "      <th>cityblock_distance</th>\n",
       "      <th>jaccard_distance</th>\n",
       "      <th>canberra_distance</th>\n",
       "      <th>euclidean_distance</th>\n",
       "      <th>minkowski_distance</th>\n",
       "      <th>braycurtis_distance</th>\n",
       "      <th>skew_q1vec</th>\n",
       "      <th>skew_q2vec</th>\n",
       "      <th>kur_q1vec</th>\n",
       "      <th>kur_q2vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19866</th>\n",
       "      <td>What is a good way to spend a long weekend in ...</td>\n",
       "      <td>What is the best way to spend a weekend in Ban...</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>53</td>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>3.778034</td>\n",
       "      <td>1.0</td>\n",
       "      <td>128.590874</td>\n",
       "      <td>0.273035</td>\n",
       "      <td>0.124839</td>\n",
       "      <td>0.236917</td>\n",
       "      <td>-6.923558</td>\n",
       "      <td>-6.190262</td>\n",
       "      <td>63.793805</td>\n",
       "      <td>53.960178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38013</th>\n",
       "      <td>What does it mean if a dog vomits white foam?</td>\n",
       "      <td>What does it mean if a dog is throwing up yell...</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>77</td>\n",
       "      <td>-32</td>\n",
       "      <td>16</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>...</td>\n",
       "      <td>6.219466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>147.157158</td>\n",
       "      <td>0.445947</td>\n",
       "      <td>0.200436</td>\n",
       "      <td>0.341283</td>\n",
       "      <td>-3.553175</td>\n",
       "      <td>-4.978099</td>\n",
       "      <td>25.958704</td>\n",
       "      <td>42.166227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60509</th>\n",
       "      <td>How can you make your skin lighter?</td>\n",
       "      <td>What can I do to make my skin whiter?</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>37</td>\n",
       "      <td>-2</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>6.720695</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.431993</td>\n",
       "      <td>0.473985</td>\n",
       "      <td>0.210055</td>\n",
       "      <td>0.325232</td>\n",
       "      <td>-4.250795</td>\n",
       "      <td>-2.831428</td>\n",
       "      <td>34.080928</td>\n",
       "      <td>20.905081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73053</th>\n",
       "      <td>What is the best passive investment strategy?</td>\n",
       "      <td>What is your investment strategy?</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>33</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>5.982412</td>\n",
       "      <td>1.0</td>\n",
       "      <td>137.046347</td>\n",
       "      <td>0.435726</td>\n",
       "      <td>0.200231</td>\n",
       "      <td>0.304307</td>\n",
       "      <td>-5.354166</td>\n",
       "      <td>-3.369078</td>\n",
       "      <td>46.089431</td>\n",
       "      <td>23.742220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56738</th>\n",
       "      <td>What is the best way to start learning program...</td>\n",
       "      <td>How do I start learning programming language? ...</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4.675204</td>\n",
       "      <td>1.0</td>\n",
       "      <td>143.059820</td>\n",
       "      <td>0.340347</td>\n",
       "      <td>0.155126</td>\n",
       "      <td>0.297584</td>\n",
       "      <td>-6.921454</td>\n",
       "      <td>-6.508542</td>\n",
       "      <td>65.565907</td>\n",
       "      <td>58.963952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               question1  \\\n",
       "19866  What is a good way to spend a long weekend in ...   \n",
       "38013      What does it mean if a dog vomits white foam?   \n",
       "60509                How can you make your skin lighter?   \n",
       "73053      What is the best passive investment strategy?   \n",
       "56738  What is the best way to start learning program...   \n",
       "\n",
       "                                               question2  is_duplicate  \\\n",
       "19866  What is the best way to spend a weekend in Ban...             1   \n",
       "38013  What does it mean if a dog is throwing up yell...             1   \n",
       "60509              What can I do to make my skin whiter?             1   \n",
       "73053                  What is your investment strategy?             0   \n",
       "56738  How do I start learning programming language? ...             1   \n",
       "\n",
       "       len_q1  len_q2  diff_len  len_char_q1  len_char_q2  len_word_q1  \\\n",
       "19866      67      53        14           20           20           14   \n",
       "38013      45      77       -32           16           23           10   \n",
       "60509      35      37        -2           19           18            7   \n",
       "73053      45      33        12           16           16            7   \n",
       "56738      71      70         1           21           21           12   \n",
       "\n",
       "       len_word_q2    ...      cityblock_distance  jaccard_distance  \\\n",
       "19866           11    ...                3.778034               1.0   \n",
       "38013           17    ...                6.219466               1.0   \n",
       "60509            9    ...                6.720695               1.0   \n",
       "73053            5    ...                5.982412               1.0   \n",
       "56738           12    ...                4.675204               1.0   \n",
       "\n",
       "       canberra_distance  euclidean_distance  minkowski_distance  \\\n",
       "19866         128.590874            0.273035            0.124839   \n",
       "38013         147.157158            0.445947            0.200436   \n",
       "60509         137.431993            0.473985            0.210055   \n",
       "73053         137.046347            0.435726            0.200231   \n",
       "56738         143.059820            0.340347            0.155126   \n",
       "\n",
       "       braycurtis_distance  skew_q1vec  skew_q2vec  kur_q1vec  kur_q2vec  \n",
       "19866             0.236917   -6.923558   -6.190262  63.793805  53.960178  \n",
       "38013             0.341283   -3.553175   -4.978099  25.958704  42.166227  \n",
       "60509             0.325232   -4.250795   -2.831428  34.080928  20.905081  \n",
       "73053             0.304307   -5.354166   -3.369078  46.089431  23.742220  \n",
       "56738             0.297584   -6.921454   -6.508542  65.565907  58.963952  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
